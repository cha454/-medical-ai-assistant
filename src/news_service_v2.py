"""
Service d'actualit√©s hybride pour l'assistant m√©dical
Combine GNews API (international) + RSS Feeds (Afrique)
"""

import requests
import feedparser
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List

class NewsServiceV2:
    def __init__(self):
        # Cl√© API GNews (optionnelle - 100 requ√™tes/jour gratuit)
        self.gnews_key = os.environ.get('GNEWS_API_KEY')
        
        # URLs des API
        self.gnews_url = "https://gnews.io/api/v4/search"
        
        # Flux RSS pour les actualit√©s africaines
        self.african_rss_feeds = {
            "gabon": [
                "https://www.gabonreview.com/feed/",
                "https://www.agpgabon.ga/feed/",
            ],
            "afrique_generale": [
                "https://www.jeuneafrique.com/feed/",
                "https://www.bbc.com/afrique/rss.xml",
                "https://www.rfi.fr/fr/afrique/rss",
                "https://africanews.com/feed/",
            ],
            "maroc": [
                "https://www.le360.ma/fr/rss",
                "https://www.hespress.com/feed",
            ],
            "algerie": [
                "https://www.tsa-algerie.com/feed/",
            ],
            "tunisie": [
                "https://www.tunisienumerique.com/feed/",
            ],
            "senegal": [
                "https://www.dakaractu.com/feed",
            ],
            "cote_ivoire": [
                "https://www.connectionivoirienne.net/feed/",
            ],
            "cameroun": [
                "https://www.camer.be/feed/",
            ],
        }
        
        # Cat√©gories disponibles
        self.categories = {
            "sant√©": "health",
            "sante": "health",
            "health": "health",
            "sport": "sports",
            "sports": "sports",
            "tech": "technology",
            "technologie": "technology",
            "technology": "technology",
            "science": "science",
            "business": "business",
            "affaires": "business",
            "divertissement": "entertainment",
            "entertainment": "entertainment"
        }
        
        # Pays africains
        self.african_countries = [
            "gabon", "maroc", "alg√©rie", "algerie", "tunisie", "s√©n√©gal", "senegal",
            "c√¥te d'ivoire", "cote d'ivoire", "cameroun", "mali", "burkina faso",
            "niger", "tchad", "congo", "rdc", "guin√©e", "guinee", "b√©nin", "benin", "togo"
        ]
        
        print(f"‚úì Service actualit√©s hybride initialis√© (GNews + RSS)")
    
    def is_available(self) -> bool:
        """V√©rifie si au moins un service est disponible"""
        return True  # RSS est toujours disponible
    
    def is_news_request(self, text: str) -> bool:
        """D√©tecte si le message est une demande d'actualit√©s"""
        text_lower = text.lower()
        
        keywords = [
            "actualit√©", "actualit√©s", "actualite", "actualites",
            "news", "nouvelles", "infos", "informations",
            "derni√®res nouvelles", "quoi de neuf", "derniers √©v√©nements",
            "actualit√© de", "actualit√© du", "actualit√© de la",
            "news about", "news on", "news of"
        ]
        
        return any(keyword in text_lower for keyword in keywords)
    
    def get_news_hybrid(self, query: str, country: Optional[str] = None, category: Optional[str] = None) -> Dict[str, Any]:
        """R√©cup√®re les actualit√©s en combinant GNews et RSS"""
        articles = []
        sources_used = []
        
        # D√©tecter si c'est une recherche africaine
        is_african = False
        if query:
            query_lower = query.lower()
            is_african = any(country_name in query_lower for country_name in self.african_countries)
        
        # 1. Si recherche africaine ‚Üí Priorit√© RSS
        if is_african:
            print(f"üåç Recherche africaine d√©tect√©e ‚Üí Utilisation RSS en priorit√©")
            rss_articles = self._get_rss_news(query)
            if rss_articles:
                articles.extend(rss_articles)
                sources_used.append("RSS Feeds (Afrique)")
        
        # 2. Compl√©ter avec GNews (si disponible et pas trop d'articles RSS)
        if self.gnews_key and len(articles) < 5:
            print(f"üì∞ Compl√©ment avec GNews API")
            gnews_articles = self._get_gnews(query, category)
            if gnews_articles:
                articles.extend(gnews_articles)
                sources_used.append("GNews API")
        
        # 3. Si pas de GNews et pas assez d'articles RSS ‚Üí Plus de RSS
        if not self.gnews_key and len(articles) < 5:
            print(f"üì° Recherche RSS √©tendue")
            more_rss = self._get_rss_news(query, extended=True)
            if more_rss:
                articles.extend(more_rss)
        
        # D√©dupliquer et limiter √† 20 articles
        articles = self._deduplicate_articles(articles)[:20]
        
        if not articles:
            return {
                "success": False,
                "error": "Aucun article",
                "message": "Aucune actualit√© trouv√©e pour cette recherche.",
                "suggestion": "Essaie une recherche plus g√©n√©rale ou un autre sujet."
            }
        
        return {
            "success": True,
            "articles": articles[:16],  # Limiter √† 16 pour une grille de 4x4
            "total": len(articles),
            "sources": sources_used,
            "query": query
        }
    
    def _get_gnews(self, query: str, category: Optional[str] = None) -> List[Dict]:
        """R√©cup√®re les actualit√©s depuis GNews API"""
        if not self.gnews_key:
            return []
        
        try:
            params = {
                "apikey": self.gnews_key,
                "q": query,
                "lang": "fr",
                "max": 10,
                "sortby": "publishedAt"
            }
            
            if category:
                params["topic"] = category
            
            print(f"üì∞ GNews Request: {query}")
            response = requests.get(self.gnews_url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                articles = []
                
                for article in data.get("articles", []):
                    articles.append({
                        "title": article.get("title"),
                        "description": article.get("description"),
                        "url": article.get("url"),
                        "source": {"name": article.get("source", {}).get("name", "GNews")},
                        "publishedAt": article.get("publishedAt"),
                        "image": article.get("image"),
                        "video": None
                    })
                
                print(f"   ‚úì {len(articles)} articles GNews trouv√©s")
                return articles
            else:
                print(f"   ‚ö†Ô∏è GNews Error: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"   ‚ùå GNews Exception: {e}")
            return []
    
    def _get_rss_news(self, query: str, extended: bool = False) -> List[Dict]:
        """R√©cup√®re les actualit√©s depuis les flux RSS africains"""
        articles = []
        query_lower = query.lower()
        
        # D√©terminer quels flux RSS utiliser
        feeds_to_check = []
        
        # Recherche sp√©cifique par pays
        for country, feeds in self.african_rss_feeds.items():
            if country.replace("_", " ") in query_lower:
                feeds_to_check.extend(feeds)
                print(f"üåç Flux RSS {country}: {len(feeds)} sources")
        
        # Si pas de pays sp√©cifique ou extended, utiliser les flux g√©n√©raux
        if not feeds_to_check or extended:
            feeds_to_check.extend(self.african_rss_feeds["afrique_generale"])
        
        # Limiter le nombre de flux pour ne pas √™tre trop lent
        feeds_to_check = list(set(feeds_to_check))[:5]  # Max 5 flux
        
        # Parser chaque flux RSS
        for feed_url in feeds_to_check:
            try:
                print(f"üì° Parsing RSS: {feed_url}")
                feed = feedparser.parse(feed_url)
                
                for entry in feed.entries[:5]:  # Max 5 articles par flux
                    # Filtrer par mots-cl√©s si recherche sp√©cifique
                    title = entry.get("title", "")
                    description = entry.get("description", "") or entry.get("summary", "")
                    
                    # Si recherche sp√©cifique, v√©rifier que l'article correspond
                    if query and len(query) > 3:
                        if query_lower not in title.lower() and query_lower not in description.lower():
                            continue
                    
                    # Extraire la date
                    published = entry.get("published", "") or entry.get("updated", "")
                    
                    # Extraire l'image (plusieurs m√©thodes)
                    image_url = self._extract_image_from_entry(entry)
                    
                    # Extraire la vid√©o (si disponible)
                    video_url = self._extract_video_from_entry(entry)
                    
                    articles.append({
                        "title": title,
                        "description": description[:300] if description else "",
                        "url": entry.get("link", ""),
                        "source": {"name": feed.feed.get("title", "RSS Feed")},
                        "publishedAt": published,
                        "image": image_url,
                        "video": video_url
                    })
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è RSS Error ({feed_url}): {e}")
                continue
        
        print(f"   ‚úì {len(articles)} articles RSS trouv√©s")
        return articles
    
    def _extract_image_from_entry(self, entry) -> Optional[str]:
        """Extrait l'image d'une entr√©e RSS (plusieurs m√©thodes)"""
        import re
        
        # M√©thode 1: media_content (standard)
        if entry.get("media_content"):
            for media in entry.get("media_content", []):
                if media.get("url"):
                    return media.get("url")
        
        # M√©thode 2: media_thumbnail
        if entry.get("media_thumbnail"):
            for thumb in entry.get("media_thumbnail", []):
                if thumb.get("url"):
                    return thumb.get("url")
        
        # M√©thode 3: enclosures (pi√®ces jointes)
        if entry.get("enclosures"):
            for enclosure in entry.get("enclosures", []):
                if enclosure.get("type", "").startswith("image/"):
                    return enclosure.get("href") or enclosure.get("url")
        
        # M√©thode 4: Chercher dans le contenu HTML
        content = entry.get("content", [{}])[0].get("value", "") or entry.get("description", "") or entry.get("summary", "")
        if content:
            # Chercher les balises <img>
            img_matches = re.findall(r'<img[^>]+src=["\']([^"\']+)["\']', content, re.IGNORECASE)
            if img_matches:
                # Filtrer les images trop petites (probablement des ic√¥nes)
                for img_url in img_matches:
                    if not any(x in img_url.lower() for x in ['icon', 'logo', 'avatar', 'pixel', '1x1']):
                        return img_url
        
        # M√©thode 5: Champ image direct
        if entry.get("image"):
            if isinstance(entry.get("image"), dict):
                return entry.get("image", {}).get("href") or entry.get("image", {}).get("url")
            elif isinstance(entry.get("image"), str):
                return entry.get("image")
        
        # M√©thode 6: og:image dans les liens
        if entry.get("links"):
            for link in entry.get("links", []):
                if link.get("type", "").startswith("image/"):
                    return link.get("href")
        
        return None
    
    def _extract_video_from_entry(self, entry) -> Optional[str]:
        """Extrait une vid√©o d'une entr√©e RSS"""
        import re
        
        # M√©thode 1: media_content (type video)
        if entry.get("media_content"):
            for media in entry.get("media_content", []):
                if media.get("type", "").startswith("video/"):
                    return media.get("url")
        
        # M√©thode 2: Chercher des iframes YouTube ou des balises <video> dans le contenu
        content = entry.get("content", [{}])[0].get("value", "") or entry.get("description", "") or entry.get("summary", "")
        if content:
            # YouTube iframe
            yt_match = re.search(r'src=["\'](https?://(?:www\.)?(?:youtube\.com/embed/|player\.vimeo\.com/video/|dailymotion\.com/embed/video/)[^"\']+)["\']', content)
            if yt_match:
                return yt_match.group(1)
            
            # Balise <video>
            video_match = re.search(r'<video[^>]+src=["\']([^"\']+)["\']', content)
            if video_match:
                return video_match.group(1)
        
        return None

    def _deduplicate_articles(self, articles: List[Dict]) -> List[Dict]:
        """Supprime les articles en double (m√™me titre)"""
        seen_titles = set()
        unique_articles = []
        
        for article in articles:
            title = article.get("title", "").lower()
            if title and title not in seen_titles:
                seen_titles.add(title)
                unique_articles.append(article)
        
        return unique_articles
    
    def parse_and_get_news(self, text: str) -> Dict[str, Any]:
        """Parse le texte et r√©cup√®re les actualit√©s"""
        text_lower = text.lower()
        
        # D√©tecter une recherche sp√©cifique
        query = None
        import re
        
        search_patterns = [
            r"actualit√©s?\s+(?:sur|de|du|de\s+la|concernant)\s+(.+)",
            r"news\s+(?:about|on|of)\s+(.+)",
            r"infos?\s+(?:sur|de|du|concernant)\s+(.+)",
            r"derni√®res?\s+(?:actualit√©s?|news|infos?)\s+(?:sur|de|du|de\s+la)\s+(.+)"
        ]
        
        for pattern in search_patterns:
            match = re.search(pattern, text_lower)
            if match:
                query = match.group(1).strip()
                query = query.replace("?", "").replace("!", "").strip()
                print(f"üîç Recherche d√©tect√©e: '{query}'")
                break
        
        # Si pas de recherche sp√©cifique, recherche g√©n√©rale
        if not query:
            query = "actualit√©s"
        
        # D√©tecter la cat√©gorie
        category = None
        for cat_name, cat_code in self.categories.items():
            if cat_name in text_lower:
                category = cat_code
                break
        
        return self.get_news_hybrid(query=query, category=category)
    
    def format_response(self, news_result: Dict[str, Any], original_query: str) -> str:
        """Formate la r√©ponse pour l'utilisateur avec grille HTML"""
        if not news_result["success"]:
            return f"""üì∞ **Actualit√©s**

‚ùå Je n'ai pas trouv√© d'actualit√©s r√©centes.

**Raison :** {news_result.get('message', 'Erreur inconnue')}

**üí° Suggestions :**
‚Ä¢ Essaie une recherche plus g√©n√©rale
‚Ä¢ V√©rifie l'orthographe
‚Ä¢ Demande des actualit√©s sur un autre sujet

**Exemples :**
‚Ä¢ "Actualit√©s Afrique"
‚Ä¢ "Actualit√©s sant√©"
‚Ä¢ "News sport"
‚Ä¢ "Actualit√©s Gabon"

Reformule ta question et je t'aiderai ! üòä"""
        
        articles = news_result["articles"]
        sources = news_result.get("sources", [])
        
        # En-t√™te en Markdown
        response = '# üì∞ Derni√®res Actualit√©s\n\n'
        
        if sources:
            response += f'**Sources :** {", ".join(sources)}\n\n'
        
        response += '---\n\n'
        
        # Grille HTML (Marked.js laisse passer le HTML)
        response += '<div class="news-grid">\n\n'
        
        # Articles en HTML pour la grille
        for i, article in enumerate(articles, 1):
            title = article.get("title", "Sans titre")
            description = article.get("description", "")
            source = article.get("source", {}).get("name", "Source inconnue")
            url = article.get("url", "")
            published_at = article.get("publishedAt", "")
            image_url = article.get("image", "")
            video_url = article.get("video", "")
            
            # Formater la date
            date_str = ""
            if published_at:
                try:
                    for fmt in ["%Y-%m-%dT%H:%M:%SZ", "%a, %d %b %Y %H:%M:%S %z", "%Y-%m-%d %H:%M:%S"]:
                        try:
                            date_obj = datetime.strptime(published_at[:19], fmt[:19])
                            date_str = date_obj.strftime("%d/%m/%Y %H:%M")
                            break
                        except:
                            continue
                except:
                    date_str = published_at[:10] if len(published_at) >= 10 else ""
            
            # Carte d'article en HTML
            response += '<div class="news-card">\n'
            
            # Vid√©o, Image ou placeholder
            if video_url:
                if any(x in video_url for x in ["youtube.com/embed", "player.vimeo.com", "dailymotion.com/embed"]):
                    response += f'  <div class="video-container"><iframe src="{video_url}" allowfullscreen></iframe></div>\n'
                else:
                    response += f'  <video src="{video_url}" controls class="news-video"></video>\n'
            elif image_url:
                response += f'  <div class="news-image" style="background-image: url(\'{image_url}\')"></div>\n'
            else:
                response += '  <div class="news-image news-placeholder">üì∞</div>\n'
            
            # Contenu
            response += '  <div class="news-content">\n'
            response += f'    <h4 class="news-title">{title}</h4>\n'
            
            if description:
                desc_short = description[:150] + '...' if len(description) > 150 else description
                response += f'    <p class="news-description">{desc_short}</p>\n'
            
            response += '    <div class="news-meta">\n'
            response += f'      <span class="news-source">üì∞ {source}</span>\n'
            if date_str:
                response += f'      <span class="news-date">üìÖ {date_str}</span>\n'
            response += '    </div>\n'
            
            if url:
                response += f'    <a href="{url}" target="_blank" class="news-link">üîó Lire l\'article</a>\n'
            
            response += '  </div>\n'
            response += '</div>\n\n'
        
        response += '</div>\n\n'  # Fin de la grille
        
        # Footer en Markdown
        response += '---\n\n'
        response += 'üí° **Autres cat√©gories :** Sant√© ‚Ä¢ Sport ‚Ä¢ Tech ‚Ä¢ Science ‚Ä¢ Business\n\n'
        response += 'Veux-tu des actualit√©s sur un sujet sp√©cifique ?'
        
        return response

# Instance globale
news_service_v2 = NewsServiceV2()

# Test
if __name__ == "__main__":
    service = NewsServiceV2()
    
    print("=== Test: Actualit√©s Gabon ===")
    result = service.parse_and_get_news("actualit√©s du Gabon")
    print(service.format_response(result, "actualit√©s du Gabon"))
