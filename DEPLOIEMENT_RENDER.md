# üöÄ Guide de d√©ploiement sur Render

## ‚úÖ Votre application est pr√™te !

Tous les fichiers n√©cessaires sont en place. Suivez ce guide √©tape par √©tape.

## üìã Pr√©requis

- Un compte GitHub (gratuit)
- Un compte Render (gratuit) : https://render.com/
- Votre cl√© API GLM-4 (ou Google Gemini)

## üîß √âtape 1 : Pr√©parer le d√©p√¥t GitHub

### 1.1 Cr√©er un fichier .gitignore

Cr√©ez un fichier `.gitignore` √† la racine du projet :

```
# Environnement Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
ENV/
build/
dist/
*.egg-info/

# Variables d'environnement (IMPORTANT!)
.env

# Base de donn√©es locale
*.db
*.sqlite
*.sqlite3

# IDE
.vscode/
.idea/
*.swp
*.swo

# Logs
*.log

# OS
.DS_Store
Thumbs.db
```

### 1.2 Cr√©er un d√©p√¥t GitHub

1. Allez sur https://github.com/new
2. Nommez votre d√©p√¥t : `medical-ai-assistant`
3. Choisissez "Public" ou "Private"
4. **NE PAS** initialiser avec README (vous en avez d√©j√† un)
5. Cliquez "Create repository"

### 1.3 Pousser votre code

Dans votre terminal (dans le dossier `medical-ai-assistant`) :

```bash
git init
git add .
git commit -m "Initial commit - Medical AI Assistant with GLM-4"
git branch -M main
git remote add origin https://github.com/VOTRE_USERNAME/medical-ai-assistant.git
git push -u origin main
```

**‚ö†Ô∏è IMPORTANT** : V√©rifiez que le fichier `.env` n'est PAS dans GitHub !

## üåê √âtape 2 : D√©ployer sur Render

### 2.1 Cr√©er un nouveau Web Service

1. Allez sur https://dashboard.render.com/
2. Cliquez sur "New +" ‚Üí "Web Service"
3. Connectez votre compte GitHub si ce n'est pas fait
4. S√©lectionnez votre d√©p√¥t `medical-ai-assistant`
5. Cliquez "Connect"

### 2.2 Configuration du service

Remplissez les champs suivants :

**Informations de base :**
- **Name** : `medical-ai-assistant` (ou votre choix)
- **Region** : Choisissez la plus proche (Europe West pour la France)
- **Branch** : `main`
- **Root Directory** : Laissez vide
- **Runtime** : `Python 3`

**Build & Deploy :**
- **Build Command** : 
  ```bash
  pip install -r requirements.txt
  ```

- **Start Command** :
  ```bash
  gunicorn app:app
  ```

**Plan :**
- S√©lectionnez **"Free"** (gratuit, 750h/mois)

### 2.3 Variables d'environnement

Cliquez sur "Advanced" puis "Add Environment Variable".

Ajoutez ces variables **UNE PAR UNE** :

#### Variables obligatoires :

| Key | Value | Description |
|-----|-------|-------------|
| `SECRET_KEY` | `votre-cle-secrete-aleatoire-123` | Cl√© secr√®te Flask (changez-la!) |
| `FLASK_ENV` | `production` | Mode production |
| `GLM_API_KEY` | `votre_cle_glm4` | Votre cl√© API GLM-4 |

#### Variables optionnelles :

| Key | Value | Description |
|-----|-------|-------------|
| `GOOGLE_API_KEY` | `votre_cle_google` | Backup si GLM-4 √©choue |
| `SENDGRID_API_KEY` | `votre_cle_sendgrid` | Pour les emails (optionnel) |
| `SENDGRID_FROM_EMAIL` | `votre@email.com` | Email exp√©diteur |

**üí° Astuce** : Pour g√©n√©rer une SECRET_KEY s√©curis√©e :
```python
import secrets
print(secrets.token_hex(32))
```

### 2.4 Lancer le d√©ploiement

1. Cliquez sur "Create Web Service"
2. Render va :
   - Cloner votre d√©p√¥t
   - Installer les d√©pendances
   - D√©marrer l'application
3. Attendez 5-10 minutes (premi√®re fois)

### 2.5 V√©rifier le d√©ploiement

Une fois le d√©ploiement termin√© :

1. Vous verrez "Live" en vert
2. Cliquez sur l'URL (ex: `https://medical-ai-assistant.onrender.com`)
3. Testez l'endpoint de sant√© : `https://votre-url.onrender.com/api/health`

Vous devriez voir :
```json
{
  "status": "healthy",
  "message": "Assistant M√©dical IA op√©rationnel",
  "version": "2.0.0"
}
```

## üéØ √âtape 3 : Tester votre API

### Test 1 : Page d'accueil
```
https://votre-url.onrender.com/
```

### Test 2 : Interface de chat
```
https://votre-url.onrender.com/chat
```

### Test 3 : API Chat (avec curl)
```bash
curl -X POST https://votre-url.onrender.com/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Bonjour, quels sont les sympt√¥mes de la grippe?", "language": "fr"}'
```

### Test 4 : V√©rifier le provider LLM
Regardez les logs dans Render :
- Allez dans "Logs"
- Cherchez : `‚úì LLM Provider initialis√©: glm`

## üîÑ √âtape 4 : Mises √† jour

Pour mettre √† jour votre application :

```bash
# Faites vos modifications
git add .
git commit -m "Description des changements"
git push
```

Render red√©ploiera automatiquement ! üéâ

## ‚öôÔ∏è Configuration avanc√©e

### Augmenter les performances

Dans Render, vous pouvez :
- Passer au plan payant pour plus de RAM/CPU
- Activer "Auto-Deploy" (d√©j√† activ√© par d√©faut)
- Configurer des "Health Check Paths" : `/api/health`

### Ajouter un domaine personnalis√©

1. Dans Render, allez dans "Settings"
2. Section "Custom Domain"
3. Ajoutez votre domaine
4. Configurez les DNS selon les instructions

### Monitoring

Render fournit :
- **Logs en temps r√©el** : Onglet "Logs"
- **M√©triques** : CPU, RAM, requ√™tes
- **Alertes** : Configurables par email

## üêõ D√©pannage

### Erreur : "Build failed"

**Probl√®me** : D√©pendances manquantes ou incompatibles

**Solution** :
1. V√©rifiez `requirements.txt`
2. Testez localement : `pip install -r requirements.txt`
3. Regardez les logs de build dans Render

### Erreur : "Application failed to start"

**Probl√®me** : Erreur dans le code ou variables d'environnement manquantes

**Solution** :
1. V√©rifiez les logs dans Render
2. Assurez-vous que `GLM_API_KEY` est d√©finie
3. Testez localement : `python app.py`

### Erreur : "Service Unavailable"

**Probl√®me** : L'application s'est arr√™t√©e

**Solution** :
1. Regardez les logs pour voir l'erreur
2. Red√©marrez le service : "Manual Deploy" ‚Üí "Clear build cache & deploy"

### L'application est lente au premier chargement

**Normal !** Le plan gratuit de Render met l'application en veille apr√®s 15 minutes d'inactivit√©.
- Premier chargement : 30-60 secondes
- Chargements suivants : instantan√©s
- Solution : Passer au plan payant ($7/mois) pour √©viter la mise en veille

### GLM-4 ne fonctionne pas

**V√©rifications** :
1. La cl√© API est-elle correcte dans les variables d'environnement ?
2. Avez-vous du quota restant sur https://open.bigmodel.cn/ ?
3. Regardez les logs : cherchez "GLM-4 Error"

**Fallback** : Ajoutez `GOOGLE_API_KEY` comme backup

## üìä Limites du plan gratuit

| Ressource | Limite |
|-----------|--------|
| Heures/mois | 750h (suffisant pour 1 service 24/7) |
| RAM | 512 MB |
| CPU | Partag√© |
| Bande passante | Illimit√©e |
| Builds | Illimit√©s |
| Mise en veille | Apr√®s 15 min d'inactivit√© |

## üéâ F√©licitations !

Votre Assistant M√©dical IA avec GLM-4 est maintenant en ligne !

**URL de votre application** : `https://votre-nom.onrender.com`

### Prochaines √©tapes

- ‚úÖ Testez toutes les fonctionnalit√©s
- ‚úÖ Partagez l'URL avec vos utilisateurs
- ‚úÖ Surveillez les logs et les performances
- ‚úÖ Ajoutez des fonctionnalit√©s (voir README.md)

## üìö Ressources

- **Documentation Render** : https://render.com/docs
- **Support Render** : https://render.com/support
- **Documentation GLM-4** : https://open.bigmodel.cn/dev/api
- **Votre dashboard** : https://dashboard.render.com/

---

**Besoin d'aide ?** Consultez les logs dans Render ou ouvrez une issue sur GitHub.
