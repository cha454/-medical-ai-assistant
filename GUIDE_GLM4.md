# ğŸš€ Guide d'intÃ©gration GLM-4 (Zhipu AI)

GLM-4 est un excellent modÃ¨le de langage chinois dÃ©veloppÃ© par Zhipu AI. Il offre une API gratuite, rapide et performante.

## ğŸ“‹ Avantages de GLM-4

- âœ… **Gratuit** : API gratuite avec quota gÃ©nÃ©reux
- âœ… **Rapide** : Temps de rÃ©ponse trÃ¨s court
- âœ… **Performant** : QualitÃ© comparable Ã  GPT-4
- âœ… **Multilingue** : Supporte franÃ§ais, anglais, chinois, etc.
- âœ… **Facile** : IntÃ©gration simple et compatible OpenAI

## ğŸ”‘ Ã‰tape 1 : Obtenir votre clÃ© API

1. **Allez sur le site officiel** : https://open.bigmodel.cn/

2. **CrÃ©ez un compte** (gratuit)
   - Cliquez sur "æ³¨å†Œ" (S'inscrire) en haut Ã  droite
   - Utilisez votre email ou numÃ©ro de tÃ©lÃ©phone
   - VÃ©rifiez votre compte

3. **Obtenez votre API Key**
   - Connectez-vous Ã  votre compte
   - Allez dans "API Keys" ou "å¯†é’¥ç®¡ç†"
   - Cliquez sur "åˆ›å»ºæ–°çš„APIå¯†é’¥" (CrÃ©er une nouvelle clÃ© API)
   - Copiez votre clÃ© API (elle commence gÃ©nÃ©ralement par des chiffres et lettres)

4. **VÃ©rifiez votre quota**
   - Vous avez un quota gratuit pour commencer
   - Consultez votre tableau de bord pour voir votre utilisation

## âš™ï¸ Ã‰tape 2 : Configuration

1. **Ouvrez le fichier `.env`** dans votre projet

2. **Ajoutez votre clÃ© API GLM-4** :
   ```env
   # Zhipu AI GLM-4 (GRATUIT - Excellent modÃ¨le chinois)
   # Site: https://open.bigmodel.cn/
   GLM_API_KEY=votre_cle_api_ici
   ```

3. **Commentez les autres clÃ©s** (optionnel) :
   ```env
   # GOOGLE_API_KEY=
   # OPENAI_API_KEY=
   ```

4. **Sauvegardez le fichier**

## ğŸ§ª Ã‰tape 3 : Tester l'intÃ©gration

ExÃ©cutez le script de test :

```bash
python test_glm.py
```

Vous devriez voir :
```
âœ“ ClÃ© API GLM-4 dÃ©tectÃ©e
âœ“ Provider actif: glm
âœ“ LLM disponible: True
âœ… RÃ©ponse reÃ§ue
```

## ğŸš€ Ã‰tape 4 : Lancer l'application

```bash
python app.py
```

Ouvrez votre navigateur sur : http://localhost:5000

## ğŸ“Š ModÃ¨les disponibles

GLM-4 propose plusieurs modÃ¨les :

| ModÃ¨le | Description | Vitesse | CoÃ»t |
|--------|-------------|---------|------|
| `glm-4-flash` | Rapide et lÃ©ger (par dÃ©faut) | âš¡âš¡âš¡ | Gratuit |
| `glm-4` | ModÃ¨le standard | âš¡âš¡ | Gratuit |
| `glm-4-plus` | Plus performant | âš¡ | Payant |

Le modÃ¨le `glm-4-flash` est utilisÃ© par dÃ©faut car il offre le meilleur rapport vitesse/qualitÃ©.

## ğŸ”§ Personnalisation

Pour changer de modÃ¨le, modifiez dans `src/llm_provider.py` :

```python
def _call_glm(self, messages):
    data = {
        "model": "glm-4",  # Changez ici : glm-4-flash, glm-4, glm-4-plus
        "messages": messages,
        "max_tokens": 2000,
        "temperature": 0.7
    }
```

## ğŸŒ ParamÃ¨tres avancÃ©s

Vous pouvez ajuster les paramÃ¨tres de gÃ©nÃ©ration :

```python
data = {
    "model": "glm-4-flash",
    "messages": messages,
    "max_tokens": 2000,      # Longueur maximale de la rÃ©ponse
    "temperature": 0.7,      # CrÃ©ativitÃ© (0.0 = prÃ©cis, 1.0 = crÃ©atif)
    "top_p": 0.9,           # DiversitÃ© des rÃ©ponses
    "stream": False         # Streaming activÃ©/dÃ©sactivÃ©
}
```

## â“ DÃ©pannage

### Erreur : "Invalid API Key"
- VÃ©rifiez que votre clÃ© API est correcte
- Assurez-vous qu'elle est bien copiÃ©e dans `.env`
- VÃ©rifiez qu'il n'y a pas d'espaces avant/aprÃ¨s

### Erreur : "Quota exceeded"
- Vous avez dÃ©passÃ© votre quota gratuit
- Attendez le renouvellement ou ajoutez du crÃ©dit
- Consultez votre tableau de bord : https://open.bigmodel.cn/

### Erreur : "Connection timeout"
- VÃ©rifiez votre connexion internet
- Le service peut Ãªtre temporairement indisponible
- RÃ©essayez dans quelques minutes

### Le provider n'est pas "glm"
- VÃ©rifiez que `GLM_API_KEY` est bien dÃ©finie dans `.env`
- RedÃ©marrez l'application
- GLM-4 a la prioritÃ© sur les autres providers

## ğŸ“š Documentation officielle

- Site officiel : https://open.bigmodel.cn/
- Documentation API : https://open.bigmodel.cn/dev/api
- Exemples de code : https://github.com/zhipuai

## ğŸ’¡ Conseils

1. **Quota gratuit** : Utilisez-le intelligemment pour vos tests
2. **Cache** : ImplÃ©mentez un cache pour Ã©viter les appels rÃ©pÃ©tÃ©s
3. **Fallback** : Gardez un autre provider (Google Gemini) en backup
4. **Monitoring** : Surveillez votre utilisation dans le dashboard

## ğŸ‰ FÃ©licitations !

Vous avez maintenant intÃ©grÃ© GLM-4 dans votre assistant mÃ©dical IA !

Pour toute question, consultez la documentation officielle ou ouvrez une issue sur GitHub.
